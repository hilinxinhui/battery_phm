{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import LSTM, Embedding, RepeatVector, TimeDistributed, Masking, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "\n",
    "from datasets.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from datasets.model_data_handler import ModelDataHandler\n",
    "from datasets.prepare_rul_data import RulHandler\n",
    "\n",
    "from utils import metrics\n",
    "from utils.logger import Logger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]\n",
    "\n",
    "CAPACITY_THRESHOLDS = {\n",
    "  3.0 : 2.7, #th 90% - min 2.1, 70%\n",
    "  2.85 : 2.7, #th 94.7% - min 2.622, 92%\n",
    "  2.0 : 1.93, #th 96.5% - min 1.93, 96.5%\n",
    "  4.0 : 3.77, #th 94.2% - min 3.77 94.2%\n",
    "  4.9 : 4.7, #th 95.9% - min 4.3, 87.7%\n",
    "  5.0 : 4.5 #th 90% - min 3.63, 72.6%\n",
    "}\n",
    "N_CYCLE = 500\n",
    "WARMUP_TRAIN = 15\n",
    "WARMUP_TEST = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxh/battery_phm/notebooks/experiments/../../datasets/model_data_handler.py:91: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集\n",
    "data_root_path = \"../../data/raw_data/unibo/\"\n",
    "\n",
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_root_path\n",
    ")\n",
    "\n",
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()\n",
    "\n",
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(train_names, test_names)\n",
    "\n",
    "train_y = rul_handler.prepare_y_future(train_names, train_battery_range, train_y_soh, current_train, time_train, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_train\"]\n",
    "del globals()[\"time_train\"]\n",
    "test_y = rul_handler.prepare_y_future(test_names, test_battery_range, test_y_soh, current_test, time_test, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_test\"]\n",
    "del globals()[\"time_test\"]\n",
    "train_x, test_x = rul_handler.compress_cycle(train_x, test_x)\n",
    "\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.fit_and_normalize(train_x, test_x)\n",
    "train_x = rul_handler.battery_life_to_time_series(train_x, N_CYCLE, train_battery_range)\n",
    "test_x = rul_handler.battery_life_to_time_series(test_x, N_CYCLE, test_battery_range)\n",
    "\n",
    "train_x, train_y, train_battery_range, train_y_soh = rul_handler.delete_initial(train_x, train_y, train_battery_range, train_y_soh, WARMUP_TRAIN)\n",
    "test_x, test_y, test_battery_range, test_y_soh = rul_handler.delete_initial(test_x, test_y, test_battery_range, test_y_soh, WARMUP_TEST)\n",
    "\n",
    "# first one is SOH, we keep only RUL\n",
    "train_y = train_y[:,1]\n",
    "test_y = test_y[:,1]\n",
    "\n",
    "y_norm = rul_handler.Normalization()\n",
    "train_y, test_y = y_norm.fit_and_normalize(train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 500, 6)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 500, 128)          69120     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,801\n",
      "Trainable params: 124,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "IS_TRAINING = False\n",
    "RESULT_NAME = \"lstm_rul_unibo_powertools\"\n",
    "model_save_path = \"../../checkpoints/unibo_vit_deeplstm/\"\n",
    "\n",
    "if IS_TRAINING:\n",
    "    EXPERIMENT = \"lstm_rul_unibo_powertools\"\n",
    "\n",
    "    experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "    print(experiment_name)\n",
    "\n",
    "    # Model definition\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.000003)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "    model.add(LSTM(128, activation='selu',\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(LSTM(64, activation='selu', return_sequences=False,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(64, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(32, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=opt, loss='huber', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "    history = model.fit(train_x, train_y, \n",
    "                                epochs=500, \n",
    "                                batch_size=32, \n",
    "                                verbose=1,\n",
    "                                validation_split=0\n",
    "                               )\n",
    "    \n",
    "    model.save(model_save_path + '%s.h5' % experiment_name)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = model_save_path + '%s_history.csv' % experiment_name\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    history = history.history\n",
    "\n",
    "if not IS_TRAINING:\n",
    "    history = pd.read_csv(model_save_path + '%s_history.csv' % RESULT_NAME)\n",
    "    model = keras.models.load_model(model_save_path + '%s.h5' % RESULT_NAME)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_x, test_y, return_dict = True)\n",
    "mae, rmse = results[\"mae\"], results[\"rmse\"]\n",
    "\n",
    "test_predictions = model.predict(test_x)\n",
    "\n",
    "test_y = y_norm.denormalize(test_y)\n",
    "test_predictions = y_norm.denormalize(test_predictions)\n",
    "\n",
    "logger = Logger(\n",
    "        log_root_path=\"../../logs/\",\n",
    "        log_level=logging.DEBUG,\n",
    "        logger_name=\"unibo_deeplstm_cycle\"\n",
    "    ).get_logger()\n",
    "\n",
    "a = 0\n",
    "for index, b in enumerate(test_battery_range):\n",
    "    print(type(test_predictions[a:b, 0]))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # plt.gca().invert_xaxis()\n",
    "    plt.plot(test_predictions[a:b, 0])\n",
    "    plt.plot(test_y[a:b])\n",
    "    plt.xlabel(\"循环圈数\")\n",
    "    plt.ylabel(\"安时剩余寿命（Ah）\")\n",
    "    plt.legend([\"预测值\", \"真值\"])\n",
    "    figure_save_path = f\"../../assets/thesis_figures/chapter_5/unibo_lstm_rul_cycle_{index + 1}.jpg\"\n",
    "    plt.savefig(figure_save_path, dpi=1000, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "    mse = np.sum((test_y[a:b] - test_predictions[a:b, 0]) ** 2) / len(test_y[a:b])\n",
    "    rmse = math.sqrt(mse)\n",
    "    nrmse = rmse / (np.max(test_y[a:b]) - np.min(test_y[a:b]))\n",
    "    logger.info(f\"test dataset: {test_names[index]}, mae: {mae:7.6f}, rmse: {rmse:7.6f}, nrmse: {nrmse:7.6f}\")\n",
    "    \n",
    "    a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 13s 119ms/step\n",
      "Save log to: ../../logs/2023_05_26_22_34_unibo_deeplstm.log\n",
      "<class 'numpy.ndarray'>\n",
      "0.03586124602354996\n",
      "<class 'numpy.ndarray'>\n",
      "0.029240093406210175\n",
      "<class 'numpy.ndarray'>\n",
      "0.18134629667361432\n",
      "<class 'numpy.ndarray'>\n",
      "0.028672655409648872\n",
      "<class 'numpy.ndarray'>\n",
      "0.04712848874098896\n",
      "<class 'numpy.ndarray'>\n",
      "0.01921885707117366\n",
      "<class 'numpy.ndarray'>\n",
      "0.05168108769502674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y, return_dict = True)\n",
    "mae, rmse = results[\"mae\"], results[\"rmse\"]\n",
    "\n",
    "test_predictions = model.predict(test_x)\n",
    "\n",
    "test_y = y_norm.denormalize(test_y)\n",
    "test_predictions = y_norm.denormalize(test_predictions)\n",
    "\n",
    "logger = Logger(\n",
    "        log_root_path=\"../../logs/\",\n",
    "        log_level=logging.DEBUG,\n",
    "        logger_name=\"unibo_deeplstm_soh\"\n",
    "    ).get_logger()\n",
    "\n",
    "a = 0\n",
    "for index, b in enumerate(test_battery_range):\n",
    "    print(type(test_predictions[a:b, 0]))\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.gca().invert_xaxis()\n",
    "    # plt.plot(test_y_soh[a:b], test_predictions[a:b, 0])\n",
    "    # plt.plot(test_y_soh[a:b], test_y[a:b])\n",
    "    plt.scatter(x=test_y_soh[a:b], y=test_predictions[a:b, 0], s=2)\n",
    "    plt.scatter(x=test_y_soh[a:b], y=test_y[a:b], s=7)\n",
    "    plt.xlabel(\"放电容量（Ah）\")\n",
    "    plt.ylabel(\"安时剩余寿命（Ah）\")\n",
    "    plt.legend([\"预测值\", \"真值\"])\n",
    "    figure_save_path = f\"../../assets/thesis_figures/chapter_5/unibo_lstm_rul_soh_{index + 1}.jpg\"\n",
    "    plt.savefig(figure_save_path, dpi=1000, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "    mse = np.sum((test_y[a:b] - test_predictions[a:b, 0]) ** 2) / len(test_y[a:b])\n",
    "    rmse = math.sqrt(mse)\n",
    "    nrmse = rmse / (np.max(test_y[a:b]) - np.min(test_y[a:b]))\n",
    "    logger.info(f\"test dataset: {test_names[index]}, mae: {mae:7.6f}, rmse: {rmse:7.6f}, nrmse: {nrmse:7.6f}\")\n",
    "    \n",
    "    a = b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rul_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

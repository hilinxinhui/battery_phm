{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 13:19:18.267920: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-27 13:19:18.306608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-27 13:19:18.899383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import LSTM, Embedding, RepeatVector, TimeDistributed, Masking, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "\n",
    "from datasets.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from datasets.model_data_handler import ModelDataHandler\n",
    "from datasets.prepare_rul_data import RulHandler\n",
    "\n",
    "from utils import metrics\n",
    "from utils.logger import Logger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]\n",
    "\n",
    "CAPACITY_THRESHOLDS = {\n",
    "  3.0 : 2.7, #th 90% - min 2.1, 70%\n",
    "  2.85 : 2.7, #th 94.7% - min 2.622, 92%\n",
    "  2.0 : 1.93, #th 96.5% - min 1.93, 96.5%\n",
    "  4.0 : 3.77, #th 94.2% - min 3.77 94.2%\n",
    "  4.9 : 4.7, #th 95.9% - min 4.3, 87.7%\n",
    "  5.0 : 4.5 #th 90% - min 3.63, 72.6%\n",
    "}\n",
    "N_CYCLE = 500\n",
    "WARMUP_TRAIN = 15\n",
    "WARMUP_TEST = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxh/battery_phm/notebooks/experiments/../../datasets/model_data_handler.py:91: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集\n",
    "data_root_path = \"../../data/raw_data/unibo/\"\n",
    "\n",
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_root_path\n",
    ")\n",
    "\n",
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()\n",
    "\n",
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(train_names, test_names)\n",
    "\n",
    "train_y = rul_handler.prepare_y_future(train_names, train_battery_range, train_y_soh, current_train, time_train, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_train\"]\n",
    "del globals()[\"time_train\"]\n",
    "test_y = rul_handler.prepare_y_future(test_names, test_battery_range, test_y_soh, current_test, time_test, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_test\"]\n",
    "del globals()[\"time_test\"]\n",
    "train_x, test_x = rul_handler.compress_cycle(train_x, test_x)\n",
    "\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.fit_and_normalize(train_x, test_x)\n",
    "train_x = rul_handler.battery_life_to_time_series(train_x, N_CYCLE, train_battery_range)\n",
    "test_x = rul_handler.battery_life_to_time_series(test_x, N_CYCLE, test_battery_range)\n",
    "\n",
    "train_x, train_y, train_battery_range, train_y_soh = rul_handler.delete_initial(train_x, train_y, train_battery_range, train_y_soh, WARMUP_TRAIN)\n",
    "test_x, test_y, test_battery_range, test_y_soh = rul_handler.delete_initial(test_x, test_y, test_battery_range, test_y_soh, WARMUP_TEST)\n",
    "\n",
    "# first one is SOH, we keep only RUL\n",
    "train_y = train_y[:,1]\n",
    "test_y = test_y[:,1]\n",
    "\n",
    "y_norm = rul_handler.Normalization()\n",
    "train_y, test_y = y_norm.fit_and_normalize(train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 13:20:35.303892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43609 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 500, 6)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 500, 128)          69120     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,801\n",
      "Trainable params: 124,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "IS_TRAINING = False\n",
    "RESULT_NAME = \"lstm_rul_unibo_powertools\"\n",
    "model_save_path = \"../../checkpoints/unibo_vit_deeplstm/\"\n",
    "\n",
    "if IS_TRAINING:\n",
    "    EXPERIMENT = \"lstm_rul_unibo_powertools\"\n",
    "\n",
    "    experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "    print(experiment_name)\n",
    "\n",
    "    # Model definition\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.000003)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "    model.add(LSTM(128, activation='selu',\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(LSTM(64, activation='selu', return_sequences=False,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(64, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(32, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=opt, loss='huber', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "    history = model.fit(train_x, train_y, \n",
    "                                epochs=500, \n",
    "                                batch_size=32, \n",
    "                                verbose=1,\n",
    "                                validation_split=0\n",
    "                               )\n",
    "    \n",
    "    model.save(model_save_path + '%s.h5' % experiment_name)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = model_save_path + '%s_history.csv' % experiment_name\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    history = history.history\n",
    "\n",
    "if not IS_TRAINING:\n",
    "    history = pd.read_csv(model_save_path + '%s_history.csv' % RESULT_NAME)\n",
    "    model = keras.models.load_model(model_save_path + '%s.h5' % RESULT_NAME)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/104 [..............................] - ETA: 1:47 - loss: 0.0095 - mse: 2.4774e-04 - mae: 0.0154 - mape: 8.1123 - rmse: 0.0157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 13:20:37.089041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 13s 121ms/step - loss: 0.0096 - mse: 4.5230e-04 - mae: 0.0135 - mape: 2332894.0000 - rmse: 0.0213\n",
      "104/104 [==============================] - 13s 118ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 13:21:02,317 - unibo_deeplstm_cycle - INFO - average mae: 0.013523, average rmse: 0.021267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save log to: ../../logs/2023_05_27_13_21_unibo_deeplstm_cycle.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 13:21:02,956 - unibo_deeplstm_cycle - INFO - test dataset: 003-DM-3.0-4019-S, rmse: 3.855191, nrmse: 0.035861\n",
      "2023-05-27 13:21:03,547 - unibo_deeplstm_cycle - INFO - test dataset: 011-DM-3.0-4019-H, rmse: 3.102227, nrmse: 0.029240\n",
      "2023-05-27 13:21:04,155 - unibo_deeplstm_cycle - INFO - test dataset: 013-DM-3.0-4019-P, rmse: 10.773928, nrmse: 0.181346\n",
      "2023-05-27 13:21:04,770 - unibo_deeplstm_cycle - INFO - test dataset: 006-EE-2.85-0820-S, rmse: 10.122581, nrmse: 0.028673\n",
      "2023-05-27 13:21:05,377 - unibo_deeplstm_cycle - INFO - test dataset: 044-EE-2.85-0820-H, rmse: 13.871369, nrmse: 0.047128\n",
      "2023-05-27 13:21:05,969 - unibo_deeplstm_cycle - INFO - test dataset: 039-DP-2.00-2420-S, rmse: 8.883196, nrmse: 0.019219\n",
      "2023-05-27 13:21:06,555 - unibo_deeplstm_cycle - INFO - test dataset: 041-DM-4.00-2320-S, rmse: 4.498271, nrmse: 0.051681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y, return_dict = True)\n",
    "mae, rmse = results[\"mae\"], results[\"rmse\"]\n",
    "\n",
    "test_predictions = model.predict(test_x)\n",
    "\n",
    "test_y = y_norm.denormalize(test_y)\n",
    "test_predictions = y_norm.denormalize(test_predictions)\n",
    "\n",
    "logger = Logger(\n",
    "        log_root_path=\"../../logs/\",\n",
    "        log_level=logging.DEBUG,\n",
    "        logger_name=\"unibo_deeplstm_cycle\"\n",
    "    ).get_logger()\n",
    "\n",
    "logger.info(f\"average mae: {mae:7.6f}, average rmse: {rmse:7.6f}\")\n",
    "\n",
    "a = 0\n",
    "for index, b in enumerate(test_battery_range):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # plt.gca().invert_xaxis()\n",
    "    plt.plot(test_predictions[a:b, 0])\n",
    "    plt.plot(test_y[a:b])\n",
    "    plt.xlabel(\"循环圈数\")\n",
    "    plt.ylabel(\"安时剩余寿命（Ah）\")\n",
    "    plt.legend([\"预测值\", \"真值\"])\n",
    "    figure_save_path = f\"../../assets/thesis_figures/chapter_5/unibo_lstm_rul_cycle_{index + 1}.jpg\"\n",
    "    plt.savefig(figure_save_path, dpi=1000, bbox_inches=\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "    mse = np.sum((test_y[a:b] - test_predictions[a:b, 0]) ** 2) / len(test_y[a:b])\n",
    "    rmse = math.sqrt(mse)\n",
    "    nrmse = rmse / (np.max(test_y[a:b]) - np.min(test_y[a:b]))\n",
    "    logger.info(f\"test dataset: {test_names[index]}, rmse: {rmse:7.6f}, nrmse: {nrmse:7.6f}\")\n",
    "    \n",
    "    a = b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rul_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
